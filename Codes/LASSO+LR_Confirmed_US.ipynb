{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LASSO+LR Confirmed_US",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#importing basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from matplotlib.dates import DateFormatter\n",
        "import matplotlib.dates as mdates"
      ],
      "metadata": {
        "id": "k2qp4VjSze2h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYJYdZSnK64J"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bH7kQWeLdJC",
        "outputId": "2250b4fe-c855-4030-94a6-f95156d42e1b"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGALQqhmL4y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d08bd611-c506-4756-cf07-9856a3432cfc"
      },
      "source": [
        "cd /content/drive/\"MyDrive/\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = pd.read_csv('Colab Notebooks/Linear Regression/time_series_covid19_confirmed_US.csv')\n"
      ],
      "metadata": {
        "id": "yzbdm6DZ25Xk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "pt9uDLr5N_Lf",
        "outputId": "d8bac027-84c2-4e80-eb7e-601ee460b7a9"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           UID iso2 iso3  code3     FIPS      Admin2 Province_State  \\\n",
              "0     84001001   US  USA    840   1001.0     Autauga        Alabama   \n",
              "1     84001003   US  USA    840   1003.0     Baldwin        Alabama   \n",
              "2     84001005   US  USA    840   1005.0     Barbour        Alabama   \n",
              "3     84001007   US  USA    840   1007.0        Bibb        Alabama   \n",
              "4     84001009   US  USA    840   1009.0      Blount        Alabama   \n",
              "...        ...  ...  ...    ...      ...         ...            ...   \n",
              "3337  84056039   US  USA    840  56039.0       Teton        Wyoming   \n",
              "3338  84056041   US  USA    840  56041.0       Uinta        Wyoming   \n",
              "3339  84090056   US  USA    840  90056.0  Unassigned        Wyoming   \n",
              "3340  84056043   US  USA    840  56043.0    Washakie        Wyoming   \n",
              "3341  84056045   US  USA    840  56045.0      Weston        Wyoming   \n",
              "\n",
              "     Country_Region        Lat       Long_  ... 1/2/22  1/3/22  1/4/22  \\\n",
              "0                US  32.539527  -86.644082  ...  11184   11256   11347   \n",
              "1                US  30.727750  -87.722071  ...  40396   40549   40838   \n",
              "2                US  31.868263  -85.387129  ...   3932    3961    3999   \n",
              "3                US  32.996421  -87.125115  ...   4576    4594    4616   \n",
              "4                US  33.982109  -86.567906  ...  11338   11368   11430   \n",
              "...             ...        ...         ...  ...    ...     ...     ...   \n",
              "3337             US  43.935225 -110.589080  ...   5950    6273    6452   \n",
              "3338             US  41.287818 -110.547578  ...   4154    4173    4191   \n",
              "3339             US   0.000000    0.000000  ...      0       0       0   \n",
              "3340             US  43.904516 -107.680187  ...   1880    1886    1892   \n",
              "3341             US  43.839612 -104.567488  ...   1254    1257    1257   \n",
              "\n",
              "      1/5/22  1/6/22  1/7/22  1/8/22  1/9/22  1/10/22  1/11/22  \n",
              "0      11478   11638   11789   11856   11975    12029    12102  \n",
              "1      41312   41855   42391   42738   43285    43583    43896  \n",
              "2       4036    4101    4150    4180    4263     4305     4375  \n",
              "3       4680    4730    4815    4857    4914     4939     5007  \n",
              "4      11497   11587   11690   11749   11828    11893    11965  \n",
              "...      ...     ...     ...     ...     ...      ...      ...  \n",
              "3337    6581    6836    7025    7025    7025     7312     7533  \n",
              "3338    4220    4245    4264    4264    4264     4316     4367  \n",
              "3339       0       0       0       0       0        0        0  \n",
              "3340    1903    1909    1915    1915    1915     1923     1938  \n",
              "3341    1260    1261    1263    1263    1263     1268     1275  \n",
              "\n",
              "[3342 rows x 732 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99370a02-4209-4467-a489-fc510f1521dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UID</th>\n",
              "      <th>iso2</th>\n",
              "      <th>iso3</th>\n",
              "      <th>code3</th>\n",
              "      <th>FIPS</th>\n",
              "      <th>Admin2</th>\n",
              "      <th>Province_State</th>\n",
              "      <th>Country_Region</th>\n",
              "      <th>Lat</th>\n",
              "      <th>Long_</th>\n",
              "      <th>...</th>\n",
              "      <th>1/2/22</th>\n",
              "      <th>1/3/22</th>\n",
              "      <th>1/4/22</th>\n",
              "      <th>1/5/22</th>\n",
              "      <th>1/6/22</th>\n",
              "      <th>1/7/22</th>\n",
              "      <th>1/8/22</th>\n",
              "      <th>1/9/22</th>\n",
              "      <th>1/10/22</th>\n",
              "      <th>1/11/22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>84001001</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>Autauga</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>US</td>\n",
              "      <td>32.539527</td>\n",
              "      <td>-86.644082</td>\n",
              "      <td>...</td>\n",
              "      <td>11184</td>\n",
              "      <td>11256</td>\n",
              "      <td>11347</td>\n",
              "      <td>11478</td>\n",
              "      <td>11638</td>\n",
              "      <td>11789</td>\n",
              "      <td>11856</td>\n",
              "      <td>11975</td>\n",
              "      <td>12029</td>\n",
              "      <td>12102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84001003</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>1003.0</td>\n",
              "      <td>Baldwin</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>US</td>\n",
              "      <td>30.727750</td>\n",
              "      <td>-87.722071</td>\n",
              "      <td>...</td>\n",
              "      <td>40396</td>\n",
              "      <td>40549</td>\n",
              "      <td>40838</td>\n",
              "      <td>41312</td>\n",
              "      <td>41855</td>\n",
              "      <td>42391</td>\n",
              "      <td>42738</td>\n",
              "      <td>43285</td>\n",
              "      <td>43583</td>\n",
              "      <td>43896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84001005</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>Barbour</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>US</td>\n",
              "      <td>31.868263</td>\n",
              "      <td>-85.387129</td>\n",
              "      <td>...</td>\n",
              "      <td>3932</td>\n",
              "      <td>3961</td>\n",
              "      <td>3999</td>\n",
              "      <td>4036</td>\n",
              "      <td>4101</td>\n",
              "      <td>4150</td>\n",
              "      <td>4180</td>\n",
              "      <td>4263</td>\n",
              "      <td>4305</td>\n",
              "      <td>4375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84001007</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>Bibb</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>US</td>\n",
              "      <td>32.996421</td>\n",
              "      <td>-87.125115</td>\n",
              "      <td>...</td>\n",
              "      <td>4576</td>\n",
              "      <td>4594</td>\n",
              "      <td>4616</td>\n",
              "      <td>4680</td>\n",
              "      <td>4730</td>\n",
              "      <td>4815</td>\n",
              "      <td>4857</td>\n",
              "      <td>4914</td>\n",
              "      <td>4939</td>\n",
              "      <td>5007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84001009</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>Blount</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>US</td>\n",
              "      <td>33.982109</td>\n",
              "      <td>-86.567906</td>\n",
              "      <td>...</td>\n",
              "      <td>11338</td>\n",
              "      <td>11368</td>\n",
              "      <td>11430</td>\n",
              "      <td>11497</td>\n",
              "      <td>11587</td>\n",
              "      <td>11690</td>\n",
              "      <td>11749</td>\n",
              "      <td>11828</td>\n",
              "      <td>11893</td>\n",
              "      <td>11965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3337</th>\n",
              "      <td>84056039</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>56039.0</td>\n",
              "      <td>Teton</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>US</td>\n",
              "      <td>43.935225</td>\n",
              "      <td>-110.589080</td>\n",
              "      <td>...</td>\n",
              "      <td>5950</td>\n",
              "      <td>6273</td>\n",
              "      <td>6452</td>\n",
              "      <td>6581</td>\n",
              "      <td>6836</td>\n",
              "      <td>7025</td>\n",
              "      <td>7025</td>\n",
              "      <td>7025</td>\n",
              "      <td>7312</td>\n",
              "      <td>7533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3338</th>\n",
              "      <td>84056041</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>56041.0</td>\n",
              "      <td>Uinta</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>US</td>\n",
              "      <td>41.287818</td>\n",
              "      <td>-110.547578</td>\n",
              "      <td>...</td>\n",
              "      <td>4154</td>\n",
              "      <td>4173</td>\n",
              "      <td>4191</td>\n",
              "      <td>4220</td>\n",
              "      <td>4245</td>\n",
              "      <td>4264</td>\n",
              "      <td>4264</td>\n",
              "      <td>4264</td>\n",
              "      <td>4316</td>\n",
              "      <td>4367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3339</th>\n",
              "      <td>84090056</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>90056.0</td>\n",
              "      <td>Unassigned</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>US</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3340</th>\n",
              "      <td>84056043</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>56043.0</td>\n",
              "      <td>Washakie</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>US</td>\n",
              "      <td>43.904516</td>\n",
              "      <td>-107.680187</td>\n",
              "      <td>...</td>\n",
              "      <td>1880</td>\n",
              "      <td>1886</td>\n",
              "      <td>1892</td>\n",
              "      <td>1903</td>\n",
              "      <td>1909</td>\n",
              "      <td>1915</td>\n",
              "      <td>1915</td>\n",
              "      <td>1915</td>\n",
              "      <td>1923</td>\n",
              "      <td>1938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3341</th>\n",
              "      <td>84056045</td>\n",
              "      <td>US</td>\n",
              "      <td>USA</td>\n",
              "      <td>840</td>\n",
              "      <td>56045.0</td>\n",
              "      <td>Weston</td>\n",
              "      <td>Wyoming</td>\n",
              "      <td>US</td>\n",
              "      <td>43.839612</td>\n",
              "      <td>-104.567488</td>\n",
              "      <td>...</td>\n",
              "      <td>1254</td>\n",
              "      <td>1257</td>\n",
              "      <td>1257</td>\n",
              "      <td>1260</td>\n",
              "      <td>1261</td>\n",
              "      <td>1263</td>\n",
              "      <td>1263</td>\n",
              "      <td>1263</td>\n",
              "      <td>1268</td>\n",
              "      <td>1275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3342 rows × 732 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99370a02-4209-4467-a489-fc510f1521dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99370a02-4209-4467-a489-fc510f1521dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99370a02-4209-4467-a489-fc510f1521dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing the dataset"
      ],
      "metadata": {
        "id": "N5aERLcAz6Bv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD58suLuOIGQ",
        "outputId": "f55f542b-f399-4701-9b5f-a2aa428744dd"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3342, 732)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJVKtPT9OSni",
        "outputId": "a6138f99-294f-4ee7-9f6f-2cfa7a113d65"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fiuq59tBOd9z"
      },
      "source": [
        "\n",
        "dataf= pd.DataFrame(dataset)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "FhIcAQQVO1d3",
        "outputId": "31e10f7a-62c6-4a61-e356-87f88f10834a"
      },
      "source": [
        "dataf.describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                UID        code3          FIPS          Lat        Long_  \\\n",
              "count  3.342000e+03  3342.000000   3332.000000  3342.000000  3342.000000   \n",
              "mean   8.342992e+07   834.494913  33043.078932    36.721617   -88.642045   \n",
              "std    4.314076e+06    36.487378  18648.808931     9.079322    21.776287   \n",
              "min    1.600000e+01    16.000000     60.000000   -14.271000  -174.159600   \n",
              "25%    8.401811e+07   840.000000  19076.500000    33.896803   -97.803595   \n",
              "50%    8.402921e+07   840.000000  31012.000000    38.005610   -89.488865   \n",
              "75%    8.404612e+07   840.000000  47129.500000    41.579255   -82.313398   \n",
              "max    8.410000e+07   850.000000  99999.000000    69.314792   145.673900   \n",
              "\n",
              "           1/22/20      1/23/20      1/24/20      1/25/20      1/26/20  ...  \\\n",
              "count  3342.000000  3342.000000  3342.000000  3342.000000  3342.000000  ...   \n",
              "mean      0.000299     0.000299     0.000598     0.000598     0.001496  ...   \n",
              "std       0.017298     0.017298     0.024459     0.024459     0.038656  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "             1/2/22        1/3/22        1/4/22        1/5/22        1/6/22  \\\n",
              "count  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03   \n",
              "mean   1.648923e+04  1.683973e+04  1.707888e+04  1.726541e+04  1.750085e+04   \n",
              "std    5.503617e+04  5.621856e+04  5.691185e+04  5.759918e+04  5.854968e+04   \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%    1.682250e+03  1.703500e+03  1.716750e+03  1.733500e+03  1.756500e+03   \n",
              "50%    4.248500e+03  4.298500e+03  4.343500e+03  4.391000e+03  4.436500e+03   \n",
              "75%    1.118850e+04  1.131575e+04  1.143600e+04  1.148675e+04  1.161175e+04   \n",
              "max    1.741292e+06  1.757522e+06  1.780154e+06  1.806828e+06  1.843922e+06   \n",
              "\n",
              "             1/7/22        1/8/22        1/9/22       1/10/22       1/11/22  \n",
              "count  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03  3.342000e+03  \n",
              "mean   1.777040e+04  1.788373e+04  1.798042e+04  1.841894e+04  1.864407e+04  \n",
              "std    6.011494e+04  6.072293e+04  6.144003e+04  6.275196e+04  6.366054e+04  \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
              "25%    1.761750e+03  1.769750e+03  1.772750e+03  1.792500e+03  1.806000e+03  \n",
              "50%    4.462500e+03  4.501500e+03  4.516000e+03  4.541500e+03  4.580500e+03  \n",
              "75%    1.169300e+04  1.181175e+04  1.183625e+04  1.197175e+04  1.207750e+04  \n",
              "max    1.887526e+06  1.921890e+06  1.967443e+06  2.010964e+06  2.046208e+06  \n",
              "\n",
              "[8 rows x 726 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b9f07e9-b527-47ad-ae01-fb6cdcfea2bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UID</th>\n",
              "      <th>code3</th>\n",
              "      <th>FIPS</th>\n",
              "      <th>Lat</th>\n",
              "      <th>Long_</th>\n",
              "      <th>1/22/20</th>\n",
              "      <th>1/23/20</th>\n",
              "      <th>1/24/20</th>\n",
              "      <th>1/25/20</th>\n",
              "      <th>1/26/20</th>\n",
              "      <th>...</th>\n",
              "      <th>1/2/22</th>\n",
              "      <th>1/3/22</th>\n",
              "      <th>1/4/22</th>\n",
              "      <th>1/5/22</th>\n",
              "      <th>1/6/22</th>\n",
              "      <th>1/7/22</th>\n",
              "      <th>1/8/22</th>\n",
              "      <th>1/9/22</th>\n",
              "      <th>1/10/22</th>\n",
              "      <th>1/11/22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>3332.000000</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>3342.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "      <td>3.342000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.342992e+07</td>\n",
              "      <td>834.494913</td>\n",
              "      <td>33043.078932</td>\n",
              "      <td>36.721617</td>\n",
              "      <td>-88.642045</td>\n",
              "      <td>0.000299</td>\n",
              "      <td>0.000299</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.001496</td>\n",
              "      <td>...</td>\n",
              "      <td>1.648923e+04</td>\n",
              "      <td>1.683973e+04</td>\n",
              "      <td>1.707888e+04</td>\n",
              "      <td>1.726541e+04</td>\n",
              "      <td>1.750085e+04</td>\n",
              "      <td>1.777040e+04</td>\n",
              "      <td>1.788373e+04</td>\n",
              "      <td>1.798042e+04</td>\n",
              "      <td>1.841894e+04</td>\n",
              "      <td>1.864407e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.314076e+06</td>\n",
              "      <td>36.487378</td>\n",
              "      <td>18648.808931</td>\n",
              "      <td>9.079322</td>\n",
              "      <td>21.776287</td>\n",
              "      <td>0.017298</td>\n",
              "      <td>0.017298</td>\n",
              "      <td>0.024459</td>\n",
              "      <td>0.024459</td>\n",
              "      <td>0.038656</td>\n",
              "      <td>...</td>\n",
              "      <td>5.503617e+04</td>\n",
              "      <td>5.621856e+04</td>\n",
              "      <td>5.691185e+04</td>\n",
              "      <td>5.759918e+04</td>\n",
              "      <td>5.854968e+04</td>\n",
              "      <td>6.011494e+04</td>\n",
              "      <td>6.072293e+04</td>\n",
              "      <td>6.144003e+04</td>\n",
              "      <td>6.275196e+04</td>\n",
              "      <td>6.366054e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.600000e+01</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>-14.271000</td>\n",
              "      <td>-174.159600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.401811e+07</td>\n",
              "      <td>840.000000</td>\n",
              "      <td>19076.500000</td>\n",
              "      <td>33.896803</td>\n",
              "      <td>-97.803595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.682250e+03</td>\n",
              "      <td>1.703500e+03</td>\n",
              "      <td>1.716750e+03</td>\n",
              "      <td>1.733500e+03</td>\n",
              "      <td>1.756500e+03</td>\n",
              "      <td>1.761750e+03</td>\n",
              "      <td>1.769750e+03</td>\n",
              "      <td>1.772750e+03</td>\n",
              "      <td>1.792500e+03</td>\n",
              "      <td>1.806000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.402921e+07</td>\n",
              "      <td>840.000000</td>\n",
              "      <td>31012.000000</td>\n",
              "      <td>38.005610</td>\n",
              "      <td>-89.488865</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.248500e+03</td>\n",
              "      <td>4.298500e+03</td>\n",
              "      <td>4.343500e+03</td>\n",
              "      <td>4.391000e+03</td>\n",
              "      <td>4.436500e+03</td>\n",
              "      <td>4.462500e+03</td>\n",
              "      <td>4.501500e+03</td>\n",
              "      <td>4.516000e+03</td>\n",
              "      <td>4.541500e+03</td>\n",
              "      <td>4.580500e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.404612e+07</td>\n",
              "      <td>840.000000</td>\n",
              "      <td>47129.500000</td>\n",
              "      <td>41.579255</td>\n",
              "      <td>-82.313398</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.118850e+04</td>\n",
              "      <td>1.131575e+04</td>\n",
              "      <td>1.143600e+04</td>\n",
              "      <td>1.148675e+04</td>\n",
              "      <td>1.161175e+04</td>\n",
              "      <td>1.169300e+04</td>\n",
              "      <td>1.181175e+04</td>\n",
              "      <td>1.183625e+04</td>\n",
              "      <td>1.197175e+04</td>\n",
              "      <td>1.207750e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8.410000e+07</td>\n",
              "      <td>850.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>69.314792</td>\n",
              "      <td>145.673900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.741292e+06</td>\n",
              "      <td>1.757522e+06</td>\n",
              "      <td>1.780154e+06</td>\n",
              "      <td>1.806828e+06</td>\n",
              "      <td>1.843922e+06</td>\n",
              "      <td>1.887526e+06</td>\n",
              "      <td>1.921890e+06</td>\n",
              "      <td>1.967443e+06</td>\n",
              "      <td>2.010964e+06</td>\n",
              "      <td>2.046208e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 726 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b9f07e9-b527-47ad-ae01-fb6cdcfea2bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b9f07e9-b527-47ad-ae01-fb6cdcfea2bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b9f07e9-b527-47ad-ae01-fb6cdcfea2bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = list(dataset.columns.values)\n",
        "print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCaVaA6C3iee",
        "outputId": "ed93dce3-ac82-4876-f57f-6aed736b3b8b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['UID', 'iso2', 'iso3', 'code3', 'FIPS', 'Admin2', 'Province_State', 'Country_Region', 'Lat', 'Long_', 'Combined_Key', '1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20', '1/27/20', '1/28/20', '1/29/20', '1/30/20', '1/31/20', '2/1/20', '2/2/20', '2/3/20', '2/4/20', '2/5/20', '2/6/20', '2/7/20', '2/8/20', '2/9/20', '2/10/20', '2/11/20', '2/12/20', '2/13/20', '2/14/20', '2/15/20', '2/16/20', '2/17/20', '2/18/20', '2/19/20', '2/20/20', '2/21/20', '2/22/20', '2/23/20', '2/24/20', '2/25/20', '2/26/20', '2/27/20', '2/28/20', '2/29/20', '3/1/20', '3/2/20', '3/3/20', '3/4/20', '3/5/20', '3/6/20', '3/7/20', '3/8/20', '3/9/20', '3/10/20', '3/11/20', '3/12/20', '3/13/20', '3/14/20', '3/15/20', '3/16/20', '3/17/20', '3/18/20', '3/19/20', '3/20/20', '3/21/20', '3/22/20', '3/23/20', '3/24/20', '3/25/20', '3/26/20', '3/27/20', '3/28/20', '3/29/20', '3/30/20', '3/31/20', '4/1/20', '4/2/20', '4/3/20', '4/4/20', '4/5/20', '4/6/20', '4/7/20', '4/8/20', '4/9/20', '4/10/20', '4/11/20', '4/12/20', '4/13/20', '4/14/20', '4/15/20', '4/16/20', '4/17/20', '4/18/20', '4/19/20', '4/20/20', '4/21/20', '4/22/20', '4/23/20', '4/24/20', '4/25/20', '4/26/20', '4/27/20', '4/28/20', '4/29/20', '4/30/20', '5/1/20', '5/2/20', '5/3/20', '5/4/20', '5/5/20', '5/6/20', '5/7/20', '5/8/20', '5/9/20', '5/10/20', '5/11/20', '5/12/20', '5/13/20', '5/14/20', '5/15/20', '5/16/20', '5/17/20', '5/18/20', '5/19/20', '5/20/20', '5/21/20', '5/22/20', '5/23/20', '5/24/20', '5/25/20', '5/26/20', '5/27/20', '5/28/20', '5/29/20', '5/30/20', '5/31/20', '6/1/20', '6/2/20', '6/3/20', '6/4/20', '6/5/20', '6/6/20', '6/7/20', '6/8/20', '6/9/20', '6/10/20', '6/11/20', '6/12/20', '6/13/20', '6/14/20', '6/15/20', '6/16/20', '6/17/20', '6/18/20', '6/19/20', '6/20/20', '6/21/20', '6/22/20', '6/23/20', '6/24/20', '6/25/20', '6/26/20', '6/27/20', '6/28/20', '6/29/20', '6/30/20', '7/1/20', '7/2/20', '7/3/20', '7/4/20', '7/5/20', '7/6/20', '7/7/20', '7/8/20', '7/9/20', '7/10/20', '7/11/20', '7/12/20', '7/13/20', '7/14/20', '7/15/20', '7/16/20', '7/17/20', '7/18/20', '7/19/20', '7/20/20', '7/21/20', '7/22/20', '7/23/20', '7/24/20', '7/25/20', '7/26/20', '7/27/20', '7/28/20', '7/29/20', '7/30/20', '7/31/20', '8/1/20', '8/2/20', '8/3/20', '8/4/20', '8/5/20', '8/6/20', '8/7/20', '8/8/20', '8/9/20', '8/10/20', '8/11/20', '8/12/20', '8/13/20', '8/14/20', '8/15/20', '8/16/20', '8/17/20', '8/18/20', '8/19/20', '8/20/20', '8/21/20', '8/22/20', '8/23/20', '8/24/20', '8/25/20', '8/26/20', '8/27/20', '8/28/20', '8/29/20', '8/30/20', '8/31/20', '9/1/20', '9/2/20', '9/3/20', '9/4/20', '9/5/20', '9/6/20', '9/7/20', '9/8/20', '9/9/20', '9/10/20', '9/11/20', '9/12/20', '9/13/20', '9/14/20', '9/15/20', '9/16/20', '9/17/20', '9/18/20', '9/19/20', '9/20/20', '9/21/20', '9/22/20', '9/23/20', '9/24/20', '9/25/20', '9/26/20', '9/27/20', '9/28/20', '9/29/20', '9/30/20', '10/1/20', '10/2/20', '10/3/20', '10/4/20', '10/5/20', '10/6/20', '10/7/20', '10/8/20', '10/9/20', '10/10/20', '10/11/20', '10/12/20', '10/13/20', '10/14/20', '10/15/20', '10/16/20', '10/17/20', '10/18/20', '10/19/20', '10/20/20', '10/21/20', '10/22/20', '10/23/20', '10/24/20', '10/25/20', '10/26/20', '10/27/20', '10/28/20', '10/29/20', '10/30/20', '10/31/20', '11/1/20', '11/2/20', '11/3/20', '11/4/20', '11/5/20', '11/6/20', '11/7/20', '11/8/20', '11/9/20', '11/10/20', '11/11/20', '11/12/20', '11/13/20', '11/14/20', '11/15/20', '11/16/20', '11/17/20', '11/18/20', '11/19/20', '11/20/20', '11/21/20', '11/22/20', '11/23/20', '11/24/20', '11/25/20', '11/26/20', '11/27/20', '11/28/20', '11/29/20', '11/30/20', '12/1/20', '12/2/20', '12/3/20', '12/4/20', '12/5/20', '12/6/20', '12/7/20', '12/8/20', '12/9/20', '12/10/20', '12/11/20', '12/12/20', '12/13/20', '12/14/20', '12/15/20', '12/16/20', '12/17/20', '12/18/20', '12/19/20', '12/20/20', '12/21/20', '12/22/20', '12/23/20', '12/24/20', '12/25/20', '12/26/20', '12/27/20', '12/28/20', '12/29/20', '12/30/20', '12/31/20', '1/1/21', '1/2/21', '1/3/21', '1/4/21', '1/5/21', '1/6/21', '1/7/21', '1/8/21', '1/9/21', '1/10/21', '1/11/21', '1/12/21', '1/13/21', '1/14/21', '1/15/21', '1/16/21', '1/17/21', '1/18/21', '1/19/21', '1/20/21', '1/21/21', '1/22/21', '1/23/21', '1/24/21', '1/25/21', '1/26/21', '1/27/21', '1/28/21', '1/29/21', '1/30/21', '1/31/21', '2/1/21', '2/2/21', '2/3/21', '2/4/21', '2/5/21', '2/6/21', '2/7/21', '2/8/21', '2/9/21', '2/10/21', '2/11/21', '2/12/21', '2/13/21', '2/14/21', '2/15/21', '2/16/21', '2/17/21', '2/18/21', '2/19/21', '2/20/21', '2/21/21', '2/22/21', '2/23/21', '2/24/21', '2/25/21', '2/26/21', '2/27/21', '2/28/21', '3/1/21', '3/2/21', '3/3/21', '3/4/21', '3/5/21', '3/6/21', '3/7/21', '3/8/21', '3/9/21', '3/10/21', '3/11/21', '3/12/21', '3/13/21', '3/14/21', '3/15/21', '3/16/21', '3/17/21', '3/18/21', '3/19/21', '3/20/21', '3/21/21', '3/22/21', '3/23/21', '3/24/21', '3/25/21', '3/26/21', '3/27/21', '3/28/21', '3/29/21', '3/30/21', '3/31/21', '4/1/21', '4/2/21', '4/3/21', '4/4/21', '4/5/21', '4/6/21', '4/7/21', '4/8/21', '4/9/21', '4/10/21', '4/11/21', '4/12/21', '4/13/21', '4/14/21', '4/15/21', '4/16/21', '4/17/21', '4/18/21', '4/19/21', '4/20/21', '4/21/21', '4/22/21', '4/23/21', '4/24/21', '4/25/21', '4/26/21', '4/27/21', '4/28/21', '4/29/21', '4/30/21', '5/1/21', '5/2/21', '5/3/21', '5/4/21', '5/5/21', '5/6/21', '5/7/21', '5/8/21', '5/9/21', '5/10/21', '5/11/21', '5/12/21', '5/13/21', '5/14/21', '5/15/21', '5/16/21', '5/17/21', '5/18/21', '5/19/21', '5/20/21', '5/21/21', '5/22/21', '5/23/21', '5/24/21', '5/25/21', '5/26/21', '5/27/21', '5/28/21', '5/29/21', '5/30/21', '5/31/21', '6/1/21', '6/2/21', '6/3/21', '6/4/21', '6/5/21', '6/6/21', '6/7/21', '6/8/21', '6/9/21', '6/10/21', '6/11/21', '6/12/21', '6/13/21', '6/14/21', '6/15/21', '6/16/21', '6/17/21', '6/18/21', '6/19/21', '6/20/21', '6/21/21', '6/22/21', '6/23/21', '6/24/21', '6/25/21', '6/26/21', '6/27/21', '6/28/21', '6/29/21', '6/30/21', '7/1/21', '7/2/21', '7/3/21', '7/4/21', '7/5/21', '7/6/21', '7/7/21', '7/8/21', '7/9/21', '7/10/21', '7/11/21', '7/12/21', '7/13/21', '7/14/21', '7/15/21', '7/16/21', '7/17/21', '7/18/21', '7/19/21', '7/20/21', '7/21/21', '7/22/21', '7/23/21', '7/24/21', '7/25/21', '7/26/21', '7/27/21', '7/28/21', '7/29/21', '7/30/21', '7/31/21', '8/1/21', '8/2/21', '8/3/21', '8/4/21', '8/5/21', '8/6/21', '8/7/21', '8/8/21', '8/9/21', '8/10/21', '8/11/21', '8/12/21', '8/13/21', '8/14/21', '8/15/21', '8/16/21', '8/17/21', '8/18/21', '8/19/21', '8/20/21', '8/21/21', '8/22/21', '8/23/21', '8/24/21', '8/25/21', '8/26/21', '8/27/21', '8/28/21', '8/29/21', '8/30/21', '8/31/21', '9/1/21', '9/2/21', '9/3/21', '9/4/21', '9/5/21', '9/6/21', '9/7/21', '9/8/21', '9/9/21', '9/10/21', '9/11/21', '9/12/21', '9/13/21', '9/14/21', '9/15/21', '9/16/21', '9/17/21', '9/18/21', '9/19/21', '9/20/21', '9/21/21', '9/22/21', '9/23/21', '9/24/21', '9/25/21', '9/26/21', '9/27/21', '9/28/21', '9/29/21', '9/30/21', '10/1/21', '10/2/21', '10/3/21', '10/4/21', '10/5/21', '10/6/21', '10/7/21', '10/8/21', '10/9/21', '10/10/21', '10/11/21', '10/12/21', '10/13/21', '10/14/21', '10/15/21', '10/16/21', '10/17/21', '10/18/21', '10/19/21', '10/20/21', '10/21/21', '10/22/21', '10/23/21', '10/24/21', '10/25/21', '10/26/21', '10/27/21', '10/28/21', '10/29/21', '10/30/21', '10/31/21', '11/1/21', '11/2/21', '11/3/21', '11/4/21', '11/5/21', '11/6/21', '11/7/21', '11/8/21', '11/9/21', '11/10/21', '11/11/21', '11/12/21', '11/13/21', '11/14/21', '11/15/21', '11/16/21', '11/17/21', '11/18/21', '11/19/21', '11/20/21', '11/21/21', '11/22/21', '11/23/21', '11/24/21', '11/25/21', '11/26/21', '11/27/21', '11/28/21', '11/29/21', '11/30/21', '12/1/21', '12/2/21', '12/3/21', '12/4/21', '12/5/21', '12/6/21', '12/7/21', '12/8/21', '12/9/21', '12/10/21', '12/11/21', '12/12/21', '12/13/21', '12/14/21', '12/15/21', '12/16/21', '12/17/21', '12/18/21', '12/19/21', '12/20/21', '12/21/21', '12/22/21', '12/23/21', '12/24/21', '12/25/21', '12/26/21', '12/27/21', '12/28/21', '12/29/21', '12/30/21', '12/31/21', '1/1/22', '1/2/22', '1/3/22', '1/4/22', '1/5/22', '1/6/22', '1/7/22', '1/8/22', '1/9/22', '1/10/22', '1/11/22']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "col_value = (list(dataf.sum(axis = 0, skipna = True)))\n",
        "#print(col_value)\n",
        "df1 = pd.DataFrame(list(zip(col, col_value)),columns =['Title', 'Values'])\n",
        "\n",
        "#df1.set_index('Title',inplace=True)\n",
        "#print(df1)\n",
        "#df1.drop(df1.index[[\"Province/State\"]])\n",
        "\n",
        "data = df1.drop(df1.index)\n",
        "print(df1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2URIGisC4Naf",
        "outputId": "c9a85df2-9c5b-43a7-bb06-a921f05bb162"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title                                             Values\n",
            "0        UID                                       278822801147\n",
            "1       iso2  USUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUS...\n",
            "2       iso3  USAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAU...\n",
            "3      code3                                            2788882\n",
            "4       FIPS                                        110099539.0\n",
            "..       ...                                                ...\n",
            "726   1/6/22                                           59388686\n",
            "727   1/7/22                                           59767418\n",
            "728   1/8/22                                           60090560\n",
            "729   1/9/22                                           61556085\n",
            "730  1/10/22                                           62308472\n",
            "\n",
            "[731 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col1 = list(df1.columns.values)\n",
        "print(col1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrDH0D8Nsv41",
        "outputId": "21b6899c-e256-42a9-ec69-508c2b88dc57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Title', 'Values']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqhzmwLgPB5T"
      },
      "source": [
        "x_value=df1.iloc[11:,0:1]\n",
        "y_value=df1.iloc[11:,1:2]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UZ7kRKYH0NYN",
        "outputId": "3d017751-dfcd-4229-d6b1-a51b81de22a8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Title\n",
              "11   1/22/20\n",
              "12   1/23/20\n",
              "13   1/24/20\n",
              "14   1/25/20\n",
              "15   1/26/20\n",
              "..       ...\n",
              "726   1/6/22\n",
              "727   1/7/22\n",
              "728   1/8/22\n",
              "729   1/9/22\n",
              "730  1/10/22\n",
              "\n",
              "[720 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09ee7554-e59c-4322-bb6e-2ac86d746376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1/22/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1/23/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1/24/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1/25/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1/26/20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>1/6/22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>1/7/22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>1/8/22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>1/9/22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>1/10/22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09ee7554-e59c-4322-bb6e-2ac86d746376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09ee7554-e59c-4322-bb6e-2ac86d746376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09ee7554-e59c-4322-bb6e-2ac86d746376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4sTKJThy0P2k",
        "outputId": "1c886842-3ce5-4617-9b08-58c7acb657ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Values\n",
              "11          1\n",
              "12          2\n",
              "13          2\n",
              "14          5\n",
              "15          5\n",
              "..        ...\n",
              "726  59388686\n",
              "727  59767418\n",
              "728  60090560\n",
              "729  61556085\n",
              "730  62308472\n",
              "\n",
              "[720 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ab7986d-d7b3-4b8e-8ff7-cf43ad76db53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>59388686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>59767418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>60090560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>61556085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>62308472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ab7986d-d7b3-4b8e-8ff7-cf43ad76db53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ab7986d-d7b3-4b8e-8ff7-cf43ad76db53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ab7986d-d7b3-4b8e-8ff7-cf43ad76db53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning the dataset\n",
        "#remove the na values\n",
        "training_dataset=df1\n",
        "cleaned_dataset=training_dataset.dropna()"
      ],
      "metadata": {
        "id": "3HwfKPT30cpl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQRZ9W5u0hQd",
        "outputId": "58dc5c40-e326-4403-f55a-e08e7050a10c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(731, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "q8k7XVkx0myq",
        "outputId": "4753bfec-a5f8-48b6-a28d-a7d51115c70e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Title                                             Values\n",
              "0        UID                                       278822801147\n",
              "1       iso2  USUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUS...\n",
              "2       iso3  USAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAU...\n",
              "3      code3                                            2788882\n",
              "4       FIPS                                        110099539.0\n",
              "..       ...                                                ...\n",
              "726   1/6/22                                           59388686\n",
              "727   1/7/22                                           59767418\n",
              "728   1/8/22                                           60090560\n",
              "729   1/9/22                                           61556085\n",
              "730  1/10/22                                           62308472\n",
              "\n",
              "[731 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cda8033-692b-43f7-9db2-9a2d082066bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UID</td>\n",
              "      <td>278822801147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>iso2</td>\n",
              "      <td>USUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>iso3</td>\n",
              "      <td>USAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>code3</td>\n",
              "      <td>2788882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FIPS</td>\n",
              "      <td>110099539.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>1/6/22</td>\n",
              "      <td>59388686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>1/7/22</td>\n",
              "      <td>59767418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>1/8/22</td>\n",
              "      <td>60090560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>1/9/22</td>\n",
              "      <td>61556085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>1/10/22</td>\n",
              "      <td>62308472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>731 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cda8033-692b-43f7-9db2-9a2d082066bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cda8033-692b-43f7-9db2-9a2d082066bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cda8033-692b-43f7-9db2-9a2d082066bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_new = cleaned_dataset['Title']"
      ],
      "metadata": {
        "id": "-iCBTnqw0mvI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = cleaned_dataset['Values']"
      ],
      "metadata": {
        "id": "3LfbyzII0msx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_value1=cleaned_dataset.iloc[11:,0:1]\n",
        "y_value1=cleaned_dataset.iloc[11:,1:2]\n",
        "print(x_value1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlRyl61ruem0",
        "outputId": "688c0526-94ee-422c-96c0-d152d05d0ee8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title\n",
            "11   1/22/20\n",
            "12   1/23/20\n",
            "13   1/24/20\n",
            "14   1/25/20\n",
            "15   1/26/20\n",
            "..       ...\n",
            "726   1/6/22\n",
            "727   1/7/22\n",
            "728   1/8/22\n",
            "729   1/9/22\n",
            "730  1/10/22\n",
            "\n",
            "[720 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_value1.values.reshape(x_value1.size)"
      ],
      "metadata": {
        "id": "twpy9fvv0mqX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_value1.values.reshape(y_value1.size)"
      ],
      "metadata": {
        "id": "jaaCcjmX0mlB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates = x_value1['Title']\n",
        "#print(dates)\n",
        "date_format = [pd.to_datetime(d) for d in dates]\n",
        "print(date_format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VOoVo7knD2s",
        "outputId": "72685b39-94c0-4552-9051-ae0ff39a5864"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Timestamp('2020-01-22 00:00:00'), Timestamp('2020-01-23 00:00:00'), Timestamp('2020-01-24 00:00:00'), Timestamp('2020-01-25 00:00:00'), Timestamp('2020-01-26 00:00:00'), Timestamp('2020-01-27 00:00:00'), Timestamp('2020-01-28 00:00:00'), Timestamp('2020-01-29 00:00:00'), Timestamp('2020-01-30 00:00:00'), Timestamp('2020-01-31 00:00:00'), Timestamp('2020-02-01 00:00:00'), Timestamp('2020-02-02 00:00:00'), Timestamp('2020-02-03 00:00:00'), Timestamp('2020-02-04 00:00:00'), Timestamp('2020-02-05 00:00:00'), Timestamp('2020-02-06 00:00:00'), Timestamp('2020-02-07 00:00:00'), Timestamp('2020-02-08 00:00:00'), Timestamp('2020-02-09 00:00:00'), Timestamp('2020-02-10 00:00:00'), Timestamp('2020-02-11 00:00:00'), Timestamp('2020-02-12 00:00:00'), Timestamp('2020-02-13 00:00:00'), Timestamp('2020-02-14 00:00:00'), Timestamp('2020-02-15 00:00:00'), Timestamp('2020-02-16 00:00:00'), Timestamp('2020-02-17 00:00:00'), Timestamp('2020-02-18 00:00:00'), Timestamp('2020-02-19 00:00:00'), Timestamp('2020-02-20 00:00:00'), Timestamp('2020-02-21 00:00:00'), Timestamp('2020-02-22 00:00:00'), Timestamp('2020-02-23 00:00:00'), Timestamp('2020-02-24 00:00:00'), Timestamp('2020-02-25 00:00:00'), Timestamp('2020-02-26 00:00:00'), Timestamp('2020-02-27 00:00:00'), Timestamp('2020-02-28 00:00:00'), Timestamp('2020-02-29 00:00:00'), Timestamp('2020-03-01 00:00:00'), Timestamp('2020-03-02 00:00:00'), Timestamp('2020-03-03 00:00:00'), Timestamp('2020-03-04 00:00:00'), Timestamp('2020-03-05 00:00:00'), Timestamp('2020-03-06 00:00:00'), Timestamp('2020-03-07 00:00:00'), Timestamp('2020-03-08 00:00:00'), Timestamp('2020-03-09 00:00:00'), Timestamp('2020-03-10 00:00:00'), Timestamp('2020-03-11 00:00:00'), Timestamp('2020-03-12 00:00:00'), Timestamp('2020-03-13 00:00:00'), Timestamp('2020-03-14 00:00:00'), Timestamp('2020-03-15 00:00:00'), Timestamp('2020-03-16 00:00:00'), Timestamp('2020-03-17 00:00:00'), Timestamp('2020-03-18 00:00:00'), Timestamp('2020-03-19 00:00:00'), Timestamp('2020-03-20 00:00:00'), Timestamp('2020-03-21 00:00:00'), Timestamp('2020-03-22 00:00:00'), Timestamp('2020-03-23 00:00:00'), Timestamp('2020-03-24 00:00:00'), Timestamp('2020-03-25 00:00:00'), Timestamp('2020-03-26 00:00:00'), Timestamp('2020-03-27 00:00:00'), Timestamp('2020-03-28 00:00:00'), Timestamp('2020-03-29 00:00:00'), Timestamp('2020-03-30 00:00:00'), Timestamp('2020-03-31 00:00:00'), Timestamp('2020-04-01 00:00:00'), Timestamp('2020-04-02 00:00:00'), Timestamp('2020-04-03 00:00:00'), Timestamp('2020-04-04 00:00:00'), Timestamp('2020-04-05 00:00:00'), Timestamp('2020-04-06 00:00:00'), Timestamp('2020-04-07 00:00:00'), Timestamp('2020-04-08 00:00:00'), Timestamp('2020-04-09 00:00:00'), Timestamp('2020-04-10 00:00:00'), Timestamp('2020-04-11 00:00:00'), Timestamp('2020-04-12 00:00:00'), Timestamp('2020-04-13 00:00:00'), Timestamp('2020-04-14 00:00:00'), Timestamp('2020-04-15 00:00:00'), Timestamp('2020-04-16 00:00:00'), Timestamp('2020-04-17 00:00:00'), Timestamp('2020-04-18 00:00:00'), Timestamp('2020-04-19 00:00:00'), Timestamp('2020-04-20 00:00:00'), Timestamp('2020-04-21 00:00:00'), Timestamp('2020-04-22 00:00:00'), Timestamp('2020-04-23 00:00:00'), Timestamp('2020-04-24 00:00:00'), Timestamp('2020-04-25 00:00:00'), Timestamp('2020-04-26 00:00:00'), Timestamp('2020-04-27 00:00:00'), Timestamp('2020-04-28 00:00:00'), Timestamp('2020-04-29 00:00:00'), Timestamp('2020-04-30 00:00:00'), Timestamp('2020-05-01 00:00:00'), Timestamp('2020-05-02 00:00:00'), Timestamp('2020-05-03 00:00:00'), Timestamp('2020-05-04 00:00:00'), Timestamp('2020-05-05 00:00:00'), Timestamp('2020-05-06 00:00:00'), Timestamp('2020-05-07 00:00:00'), Timestamp('2020-05-08 00:00:00'), Timestamp('2020-05-09 00:00:00'), Timestamp('2020-05-10 00:00:00'), Timestamp('2020-05-11 00:00:00'), Timestamp('2020-05-12 00:00:00'), Timestamp('2020-05-13 00:00:00'), Timestamp('2020-05-14 00:00:00'), Timestamp('2020-05-15 00:00:00'), Timestamp('2020-05-16 00:00:00'), Timestamp('2020-05-17 00:00:00'), Timestamp('2020-05-18 00:00:00'), Timestamp('2020-05-19 00:00:00'), Timestamp('2020-05-20 00:00:00'), Timestamp('2020-05-21 00:00:00'), Timestamp('2020-05-22 00:00:00'), Timestamp('2020-05-23 00:00:00'), Timestamp('2020-05-24 00:00:00'), Timestamp('2020-05-25 00:00:00'), Timestamp('2020-05-26 00:00:00'), Timestamp('2020-05-27 00:00:00'), Timestamp('2020-05-28 00:00:00'), Timestamp('2020-05-29 00:00:00'), Timestamp('2020-05-30 00:00:00'), Timestamp('2020-05-31 00:00:00'), Timestamp('2020-06-01 00:00:00'), Timestamp('2020-06-02 00:00:00'), Timestamp('2020-06-03 00:00:00'), Timestamp('2020-06-04 00:00:00'), Timestamp('2020-06-05 00:00:00'), Timestamp('2020-06-06 00:00:00'), Timestamp('2020-06-07 00:00:00'), Timestamp('2020-06-08 00:00:00'), Timestamp('2020-06-09 00:00:00'), Timestamp('2020-06-10 00:00:00'), Timestamp('2020-06-11 00:00:00'), Timestamp('2020-06-12 00:00:00'), Timestamp('2020-06-13 00:00:00'), Timestamp('2020-06-14 00:00:00'), Timestamp('2020-06-15 00:00:00'), Timestamp('2020-06-16 00:00:00'), Timestamp('2020-06-17 00:00:00'), Timestamp('2020-06-18 00:00:00'), Timestamp('2020-06-19 00:00:00'), Timestamp('2020-06-20 00:00:00'), Timestamp('2020-06-21 00:00:00'), Timestamp('2020-06-22 00:00:00'), Timestamp('2020-06-23 00:00:00'), Timestamp('2020-06-24 00:00:00'), Timestamp('2020-06-25 00:00:00'), Timestamp('2020-06-26 00:00:00'), Timestamp('2020-06-27 00:00:00'), Timestamp('2020-06-28 00:00:00'), Timestamp('2020-06-29 00:00:00'), Timestamp('2020-06-30 00:00:00'), Timestamp('2020-07-01 00:00:00'), Timestamp('2020-07-02 00:00:00'), Timestamp('2020-07-03 00:00:00'), Timestamp('2020-07-04 00:00:00'), Timestamp('2020-07-05 00:00:00'), Timestamp('2020-07-06 00:00:00'), Timestamp('2020-07-07 00:00:00'), Timestamp('2020-07-08 00:00:00'), Timestamp('2020-07-09 00:00:00'), Timestamp('2020-07-10 00:00:00'), Timestamp('2020-07-11 00:00:00'), Timestamp('2020-07-12 00:00:00'), Timestamp('2020-07-13 00:00:00'), Timestamp('2020-07-14 00:00:00'), Timestamp('2020-07-15 00:00:00'), Timestamp('2020-07-16 00:00:00'), Timestamp('2020-07-17 00:00:00'), Timestamp('2020-07-18 00:00:00'), Timestamp('2020-07-19 00:00:00'), Timestamp('2020-07-20 00:00:00'), Timestamp('2020-07-21 00:00:00'), Timestamp('2020-07-22 00:00:00'), Timestamp('2020-07-23 00:00:00'), Timestamp('2020-07-24 00:00:00'), Timestamp('2020-07-25 00:00:00'), Timestamp('2020-07-26 00:00:00'), Timestamp('2020-07-27 00:00:00'), Timestamp('2020-07-28 00:00:00'), Timestamp('2020-07-29 00:00:00'), Timestamp('2020-07-30 00:00:00'), Timestamp('2020-07-31 00:00:00'), Timestamp('2020-08-01 00:00:00'), Timestamp('2020-08-02 00:00:00'), Timestamp('2020-08-03 00:00:00'), Timestamp('2020-08-04 00:00:00'), Timestamp('2020-08-05 00:00:00'), Timestamp('2020-08-06 00:00:00'), Timestamp('2020-08-07 00:00:00'), Timestamp('2020-08-08 00:00:00'), Timestamp('2020-08-09 00:00:00'), Timestamp('2020-08-10 00:00:00'), Timestamp('2020-08-11 00:00:00'), Timestamp('2020-08-12 00:00:00'), Timestamp('2020-08-13 00:00:00'), Timestamp('2020-08-14 00:00:00'), Timestamp('2020-08-15 00:00:00'), Timestamp('2020-08-16 00:00:00'), Timestamp('2020-08-17 00:00:00'), Timestamp('2020-08-18 00:00:00'), Timestamp('2020-08-19 00:00:00'), Timestamp('2020-08-20 00:00:00'), Timestamp('2020-08-21 00:00:00'), Timestamp('2020-08-22 00:00:00'), Timestamp('2020-08-23 00:00:00'), Timestamp('2020-08-24 00:00:00'), Timestamp('2020-08-25 00:00:00'), Timestamp('2020-08-26 00:00:00'), Timestamp('2020-08-27 00:00:00'), Timestamp('2020-08-28 00:00:00'), Timestamp('2020-08-29 00:00:00'), Timestamp('2020-08-30 00:00:00'), Timestamp('2020-08-31 00:00:00'), Timestamp('2020-09-01 00:00:00'), Timestamp('2020-09-02 00:00:00'), Timestamp('2020-09-03 00:00:00'), Timestamp('2020-09-04 00:00:00'), Timestamp('2020-09-05 00:00:00'), Timestamp('2020-09-06 00:00:00'), Timestamp('2020-09-07 00:00:00'), Timestamp('2020-09-08 00:00:00'), Timestamp('2020-09-09 00:00:00'), Timestamp('2020-09-10 00:00:00'), Timestamp('2020-09-11 00:00:00'), Timestamp('2020-09-12 00:00:00'), Timestamp('2020-09-13 00:00:00'), Timestamp('2020-09-14 00:00:00'), Timestamp('2020-09-15 00:00:00'), Timestamp('2020-09-16 00:00:00'), Timestamp('2020-09-17 00:00:00'), Timestamp('2020-09-18 00:00:00'), Timestamp('2020-09-19 00:00:00'), Timestamp('2020-09-20 00:00:00'), Timestamp('2020-09-21 00:00:00'), Timestamp('2020-09-22 00:00:00'), Timestamp('2020-09-23 00:00:00'), Timestamp('2020-09-24 00:00:00'), Timestamp('2020-09-25 00:00:00'), Timestamp('2020-09-26 00:00:00'), Timestamp('2020-09-27 00:00:00'), Timestamp('2020-09-28 00:00:00'), Timestamp('2020-09-29 00:00:00'), Timestamp('2020-09-30 00:00:00'), Timestamp('2020-10-01 00:00:00'), Timestamp('2020-10-02 00:00:00'), Timestamp('2020-10-03 00:00:00'), Timestamp('2020-10-04 00:00:00'), Timestamp('2020-10-05 00:00:00'), Timestamp('2020-10-06 00:00:00'), Timestamp('2020-10-07 00:00:00'), Timestamp('2020-10-08 00:00:00'), Timestamp('2020-10-09 00:00:00'), Timestamp('2020-10-10 00:00:00'), Timestamp('2020-10-11 00:00:00'), Timestamp('2020-10-12 00:00:00'), Timestamp('2020-10-13 00:00:00'), Timestamp('2020-10-14 00:00:00'), Timestamp('2020-10-15 00:00:00'), Timestamp('2020-10-16 00:00:00'), Timestamp('2020-10-17 00:00:00'), Timestamp('2020-10-18 00:00:00'), Timestamp('2020-10-19 00:00:00'), Timestamp('2020-10-20 00:00:00'), Timestamp('2020-10-21 00:00:00'), Timestamp('2020-10-22 00:00:00'), Timestamp('2020-10-23 00:00:00'), Timestamp('2020-10-24 00:00:00'), Timestamp('2020-10-25 00:00:00'), Timestamp('2020-10-26 00:00:00'), Timestamp('2020-10-27 00:00:00'), Timestamp('2020-10-28 00:00:00'), Timestamp('2020-10-29 00:00:00'), Timestamp('2020-10-30 00:00:00'), Timestamp('2020-10-31 00:00:00'), Timestamp('2020-11-01 00:00:00'), Timestamp('2020-11-02 00:00:00'), Timestamp('2020-11-03 00:00:00'), Timestamp('2020-11-04 00:00:00'), Timestamp('2020-11-05 00:00:00'), Timestamp('2020-11-06 00:00:00'), Timestamp('2020-11-07 00:00:00'), Timestamp('2020-11-08 00:00:00'), Timestamp('2020-11-09 00:00:00'), Timestamp('2020-11-10 00:00:00'), Timestamp('2020-11-11 00:00:00'), Timestamp('2020-11-12 00:00:00'), Timestamp('2020-11-13 00:00:00'), Timestamp('2020-11-14 00:00:00'), Timestamp('2020-11-15 00:00:00'), Timestamp('2020-11-16 00:00:00'), Timestamp('2020-11-17 00:00:00'), Timestamp('2020-11-18 00:00:00'), Timestamp('2020-11-19 00:00:00'), Timestamp('2020-11-20 00:00:00'), Timestamp('2020-11-21 00:00:00'), Timestamp('2020-11-22 00:00:00'), Timestamp('2020-11-23 00:00:00'), Timestamp('2020-11-24 00:00:00'), Timestamp('2020-11-25 00:00:00'), Timestamp('2020-11-26 00:00:00'), Timestamp('2020-11-27 00:00:00'), Timestamp('2020-11-28 00:00:00'), Timestamp('2020-11-29 00:00:00'), Timestamp('2020-11-30 00:00:00'), Timestamp('2020-12-01 00:00:00'), Timestamp('2020-12-02 00:00:00'), Timestamp('2020-12-03 00:00:00'), Timestamp('2020-12-04 00:00:00'), Timestamp('2020-12-05 00:00:00'), Timestamp('2020-12-06 00:00:00'), Timestamp('2020-12-07 00:00:00'), Timestamp('2020-12-08 00:00:00'), Timestamp('2020-12-09 00:00:00'), Timestamp('2020-12-10 00:00:00'), Timestamp('2020-12-11 00:00:00'), Timestamp('2020-12-12 00:00:00'), Timestamp('2020-12-13 00:00:00'), Timestamp('2020-12-14 00:00:00'), Timestamp('2020-12-15 00:00:00'), Timestamp('2020-12-16 00:00:00'), Timestamp('2020-12-17 00:00:00'), Timestamp('2020-12-18 00:00:00'), Timestamp('2020-12-19 00:00:00'), Timestamp('2020-12-20 00:00:00'), Timestamp('2020-12-21 00:00:00'), Timestamp('2020-12-22 00:00:00'), Timestamp('2020-12-23 00:00:00'), Timestamp('2020-12-24 00:00:00'), Timestamp('2020-12-25 00:00:00'), Timestamp('2020-12-26 00:00:00'), Timestamp('2020-12-27 00:00:00'), Timestamp('2020-12-28 00:00:00'), Timestamp('2020-12-29 00:00:00'), Timestamp('2020-12-30 00:00:00'), Timestamp('2020-12-31 00:00:00'), Timestamp('2021-01-01 00:00:00'), Timestamp('2021-01-02 00:00:00'), Timestamp('2021-01-03 00:00:00'), Timestamp('2021-01-04 00:00:00'), Timestamp('2021-01-05 00:00:00'), Timestamp('2021-01-06 00:00:00'), Timestamp('2021-01-07 00:00:00'), Timestamp('2021-01-08 00:00:00'), Timestamp('2021-01-09 00:00:00'), Timestamp('2021-01-10 00:00:00'), Timestamp('2021-01-11 00:00:00'), Timestamp('2021-01-12 00:00:00'), Timestamp('2021-01-13 00:00:00'), Timestamp('2021-01-14 00:00:00'), Timestamp('2021-01-15 00:00:00'), Timestamp('2021-01-16 00:00:00'), Timestamp('2021-01-17 00:00:00'), Timestamp('2021-01-18 00:00:00'), Timestamp('2021-01-19 00:00:00'), Timestamp('2021-01-20 00:00:00'), Timestamp('2021-01-21 00:00:00'), Timestamp('2021-01-22 00:00:00'), Timestamp('2021-01-23 00:00:00'), Timestamp('2021-01-24 00:00:00'), Timestamp('2021-01-25 00:00:00'), Timestamp('2021-01-26 00:00:00'), Timestamp('2021-01-27 00:00:00'), Timestamp('2021-01-28 00:00:00'), Timestamp('2021-01-29 00:00:00'), Timestamp('2021-01-30 00:00:00'), Timestamp('2021-01-31 00:00:00'), Timestamp('2021-02-01 00:00:00'), Timestamp('2021-02-02 00:00:00'), Timestamp('2021-02-03 00:00:00'), Timestamp('2021-02-04 00:00:00'), Timestamp('2021-02-05 00:00:00'), Timestamp('2021-02-06 00:00:00'), Timestamp('2021-02-07 00:00:00'), Timestamp('2021-02-08 00:00:00'), Timestamp('2021-02-09 00:00:00'), Timestamp('2021-02-10 00:00:00'), Timestamp('2021-02-11 00:00:00'), Timestamp('2021-02-12 00:00:00'), Timestamp('2021-02-13 00:00:00'), Timestamp('2021-02-14 00:00:00'), Timestamp('2021-02-15 00:00:00'), Timestamp('2021-02-16 00:00:00'), Timestamp('2021-02-17 00:00:00'), Timestamp('2021-02-18 00:00:00'), Timestamp('2021-02-19 00:00:00'), Timestamp('2021-02-20 00:00:00'), Timestamp('2021-02-21 00:00:00'), Timestamp('2021-02-22 00:00:00'), Timestamp('2021-02-23 00:00:00'), Timestamp('2021-02-24 00:00:00'), Timestamp('2021-02-25 00:00:00'), Timestamp('2021-02-26 00:00:00'), Timestamp('2021-02-27 00:00:00'), Timestamp('2021-02-28 00:00:00'), Timestamp('2021-03-01 00:00:00'), Timestamp('2021-03-02 00:00:00'), Timestamp('2021-03-03 00:00:00'), Timestamp('2021-03-04 00:00:00'), Timestamp('2021-03-05 00:00:00'), Timestamp('2021-03-06 00:00:00'), Timestamp('2021-03-07 00:00:00'), Timestamp('2021-03-08 00:00:00'), Timestamp('2021-03-09 00:00:00'), Timestamp('2021-03-10 00:00:00'), Timestamp('2021-03-11 00:00:00'), Timestamp('2021-03-12 00:00:00'), Timestamp('2021-03-13 00:00:00'), Timestamp('2021-03-14 00:00:00'), Timestamp('2021-03-15 00:00:00'), Timestamp('2021-03-16 00:00:00'), Timestamp('2021-03-17 00:00:00'), Timestamp('2021-03-18 00:00:00'), Timestamp('2021-03-19 00:00:00'), Timestamp('2021-03-20 00:00:00'), Timestamp('2021-03-21 00:00:00'), Timestamp('2021-03-22 00:00:00'), Timestamp('2021-03-23 00:00:00'), Timestamp('2021-03-24 00:00:00'), Timestamp('2021-03-25 00:00:00'), Timestamp('2021-03-26 00:00:00'), Timestamp('2021-03-27 00:00:00'), Timestamp('2021-03-28 00:00:00'), Timestamp('2021-03-29 00:00:00'), Timestamp('2021-03-30 00:00:00'), Timestamp('2021-03-31 00:00:00'), Timestamp('2021-04-01 00:00:00'), Timestamp('2021-04-02 00:00:00'), Timestamp('2021-04-03 00:00:00'), Timestamp('2021-04-04 00:00:00'), Timestamp('2021-04-05 00:00:00'), Timestamp('2021-04-06 00:00:00'), Timestamp('2021-04-07 00:00:00'), Timestamp('2021-04-08 00:00:00'), Timestamp('2021-04-09 00:00:00'), Timestamp('2021-04-10 00:00:00'), Timestamp('2021-04-11 00:00:00'), Timestamp('2021-04-12 00:00:00'), Timestamp('2021-04-13 00:00:00'), Timestamp('2021-04-14 00:00:00'), Timestamp('2021-04-15 00:00:00'), Timestamp('2021-04-16 00:00:00'), Timestamp('2021-04-17 00:00:00'), Timestamp('2021-04-18 00:00:00'), Timestamp('2021-04-19 00:00:00'), Timestamp('2021-04-20 00:00:00'), Timestamp('2021-04-21 00:00:00'), Timestamp('2021-04-22 00:00:00'), Timestamp('2021-04-23 00:00:00'), Timestamp('2021-04-24 00:00:00'), Timestamp('2021-04-25 00:00:00'), Timestamp('2021-04-26 00:00:00'), Timestamp('2021-04-27 00:00:00'), Timestamp('2021-04-28 00:00:00'), Timestamp('2021-04-29 00:00:00'), Timestamp('2021-04-30 00:00:00'), Timestamp('2021-05-01 00:00:00'), Timestamp('2021-05-02 00:00:00'), Timestamp('2021-05-03 00:00:00'), Timestamp('2021-05-04 00:00:00'), Timestamp('2021-05-05 00:00:00'), Timestamp('2021-05-06 00:00:00'), Timestamp('2021-05-07 00:00:00'), Timestamp('2021-05-08 00:00:00'), Timestamp('2021-05-09 00:00:00'), Timestamp('2021-05-10 00:00:00'), Timestamp('2021-05-11 00:00:00'), Timestamp('2021-05-12 00:00:00'), Timestamp('2021-05-13 00:00:00'), Timestamp('2021-05-14 00:00:00'), Timestamp('2021-05-15 00:00:00'), Timestamp('2021-05-16 00:00:00'), Timestamp('2021-05-17 00:00:00'), Timestamp('2021-05-18 00:00:00'), Timestamp('2021-05-19 00:00:00'), Timestamp('2021-05-20 00:00:00'), Timestamp('2021-05-21 00:00:00'), Timestamp('2021-05-22 00:00:00'), Timestamp('2021-05-23 00:00:00'), Timestamp('2021-05-24 00:00:00'), Timestamp('2021-05-25 00:00:00'), Timestamp('2021-05-26 00:00:00'), Timestamp('2021-05-27 00:00:00'), Timestamp('2021-05-28 00:00:00'), Timestamp('2021-05-29 00:00:00'), Timestamp('2021-05-30 00:00:00'), Timestamp('2021-05-31 00:00:00'), Timestamp('2021-06-01 00:00:00'), Timestamp('2021-06-02 00:00:00'), Timestamp('2021-06-03 00:00:00'), Timestamp('2021-06-04 00:00:00'), Timestamp('2021-06-05 00:00:00'), Timestamp('2021-06-06 00:00:00'), Timestamp('2021-06-07 00:00:00'), Timestamp('2021-06-08 00:00:00'), Timestamp('2021-06-09 00:00:00'), Timestamp('2021-06-10 00:00:00'), Timestamp('2021-06-11 00:00:00'), Timestamp('2021-06-12 00:00:00'), Timestamp('2021-06-13 00:00:00'), Timestamp('2021-06-14 00:00:00'), Timestamp('2021-06-15 00:00:00'), Timestamp('2021-06-16 00:00:00'), Timestamp('2021-06-17 00:00:00'), Timestamp('2021-06-18 00:00:00'), Timestamp('2021-06-19 00:00:00'), Timestamp('2021-06-20 00:00:00'), Timestamp('2021-06-21 00:00:00'), Timestamp('2021-06-22 00:00:00'), Timestamp('2021-06-23 00:00:00'), Timestamp('2021-06-24 00:00:00'), Timestamp('2021-06-25 00:00:00'), Timestamp('2021-06-26 00:00:00'), Timestamp('2021-06-27 00:00:00'), Timestamp('2021-06-28 00:00:00'), Timestamp('2021-06-29 00:00:00'), Timestamp('2021-06-30 00:00:00'), Timestamp('2021-07-01 00:00:00'), Timestamp('2021-07-02 00:00:00'), Timestamp('2021-07-03 00:00:00'), Timestamp('2021-07-04 00:00:00'), Timestamp('2021-07-05 00:00:00'), Timestamp('2021-07-06 00:00:00'), Timestamp('2021-07-07 00:00:00'), Timestamp('2021-07-08 00:00:00'), Timestamp('2021-07-09 00:00:00'), Timestamp('2021-07-10 00:00:00'), Timestamp('2021-07-11 00:00:00'), Timestamp('2021-07-12 00:00:00'), Timestamp('2021-07-13 00:00:00'), Timestamp('2021-07-14 00:00:00'), Timestamp('2021-07-15 00:00:00'), Timestamp('2021-07-16 00:00:00'), Timestamp('2021-07-17 00:00:00'), Timestamp('2021-07-18 00:00:00'), Timestamp('2021-07-19 00:00:00'), Timestamp('2021-07-20 00:00:00'), Timestamp('2021-07-21 00:00:00'), Timestamp('2021-07-22 00:00:00'), Timestamp('2021-07-23 00:00:00'), Timestamp('2021-07-24 00:00:00'), Timestamp('2021-07-25 00:00:00'), Timestamp('2021-07-26 00:00:00'), Timestamp('2021-07-27 00:00:00'), Timestamp('2021-07-28 00:00:00'), Timestamp('2021-07-29 00:00:00'), Timestamp('2021-07-30 00:00:00'), Timestamp('2021-07-31 00:00:00'), Timestamp('2021-08-01 00:00:00'), Timestamp('2021-08-02 00:00:00'), Timestamp('2021-08-03 00:00:00'), Timestamp('2021-08-04 00:00:00'), Timestamp('2021-08-05 00:00:00'), Timestamp('2021-08-06 00:00:00'), Timestamp('2021-08-07 00:00:00'), Timestamp('2021-08-08 00:00:00'), Timestamp('2021-08-09 00:00:00'), Timestamp('2021-08-10 00:00:00'), Timestamp('2021-08-11 00:00:00'), Timestamp('2021-08-12 00:00:00'), Timestamp('2021-08-13 00:00:00'), Timestamp('2021-08-14 00:00:00'), Timestamp('2021-08-15 00:00:00'), Timestamp('2021-08-16 00:00:00'), Timestamp('2021-08-17 00:00:00'), Timestamp('2021-08-18 00:00:00'), Timestamp('2021-08-19 00:00:00'), Timestamp('2021-08-20 00:00:00'), Timestamp('2021-08-21 00:00:00'), Timestamp('2021-08-22 00:00:00'), Timestamp('2021-08-23 00:00:00'), Timestamp('2021-08-24 00:00:00'), Timestamp('2021-08-25 00:00:00'), Timestamp('2021-08-26 00:00:00'), Timestamp('2021-08-27 00:00:00'), Timestamp('2021-08-28 00:00:00'), Timestamp('2021-08-29 00:00:00'), Timestamp('2021-08-30 00:00:00'), Timestamp('2021-08-31 00:00:00'), Timestamp('2021-09-01 00:00:00'), Timestamp('2021-09-02 00:00:00'), Timestamp('2021-09-03 00:00:00'), Timestamp('2021-09-04 00:00:00'), Timestamp('2021-09-05 00:00:00'), Timestamp('2021-09-06 00:00:00'), Timestamp('2021-09-07 00:00:00'), Timestamp('2021-09-08 00:00:00'), Timestamp('2021-09-09 00:00:00'), Timestamp('2021-09-10 00:00:00'), Timestamp('2021-09-11 00:00:00'), Timestamp('2021-09-12 00:00:00'), Timestamp('2021-09-13 00:00:00'), Timestamp('2021-09-14 00:00:00'), Timestamp('2021-09-15 00:00:00'), Timestamp('2021-09-16 00:00:00'), Timestamp('2021-09-17 00:00:00'), Timestamp('2021-09-18 00:00:00'), Timestamp('2021-09-19 00:00:00'), Timestamp('2021-09-20 00:00:00'), Timestamp('2021-09-21 00:00:00'), Timestamp('2021-09-22 00:00:00'), Timestamp('2021-09-23 00:00:00'), Timestamp('2021-09-24 00:00:00'), Timestamp('2021-09-25 00:00:00'), Timestamp('2021-09-26 00:00:00'), Timestamp('2021-09-27 00:00:00'), Timestamp('2021-09-28 00:00:00'), Timestamp('2021-09-29 00:00:00'), Timestamp('2021-09-30 00:00:00'), Timestamp('2021-10-01 00:00:00'), Timestamp('2021-10-02 00:00:00'), Timestamp('2021-10-03 00:00:00'), Timestamp('2021-10-04 00:00:00'), Timestamp('2021-10-05 00:00:00'), Timestamp('2021-10-06 00:00:00'), Timestamp('2021-10-07 00:00:00'), Timestamp('2021-10-08 00:00:00'), Timestamp('2021-10-09 00:00:00'), Timestamp('2021-10-10 00:00:00'), Timestamp('2021-10-11 00:00:00'), Timestamp('2021-10-12 00:00:00'), Timestamp('2021-10-13 00:00:00'), Timestamp('2021-10-14 00:00:00'), Timestamp('2021-10-15 00:00:00'), Timestamp('2021-10-16 00:00:00'), Timestamp('2021-10-17 00:00:00'), Timestamp('2021-10-18 00:00:00'), Timestamp('2021-10-19 00:00:00'), Timestamp('2021-10-20 00:00:00'), Timestamp('2021-10-21 00:00:00'), Timestamp('2021-10-22 00:00:00'), Timestamp('2021-10-23 00:00:00'), Timestamp('2021-10-24 00:00:00'), Timestamp('2021-10-25 00:00:00'), Timestamp('2021-10-26 00:00:00'), Timestamp('2021-10-27 00:00:00'), Timestamp('2021-10-28 00:00:00'), Timestamp('2021-10-29 00:00:00'), Timestamp('2021-10-30 00:00:00'), Timestamp('2021-10-31 00:00:00'), Timestamp('2021-11-01 00:00:00'), Timestamp('2021-11-02 00:00:00'), Timestamp('2021-11-03 00:00:00'), Timestamp('2021-11-04 00:00:00'), Timestamp('2021-11-05 00:00:00'), Timestamp('2021-11-06 00:00:00'), Timestamp('2021-11-07 00:00:00'), Timestamp('2021-11-08 00:00:00'), Timestamp('2021-11-09 00:00:00'), Timestamp('2021-11-10 00:00:00'), Timestamp('2021-11-11 00:00:00'), Timestamp('2021-11-12 00:00:00'), Timestamp('2021-11-13 00:00:00'), Timestamp('2021-11-14 00:00:00'), Timestamp('2021-11-15 00:00:00'), Timestamp('2021-11-16 00:00:00'), Timestamp('2021-11-17 00:00:00'), Timestamp('2021-11-18 00:00:00'), Timestamp('2021-11-19 00:00:00'), Timestamp('2021-11-20 00:00:00'), Timestamp('2021-11-21 00:00:00'), Timestamp('2021-11-22 00:00:00'), Timestamp('2021-11-23 00:00:00'), Timestamp('2021-11-24 00:00:00'), Timestamp('2021-11-25 00:00:00'), Timestamp('2021-11-26 00:00:00'), Timestamp('2021-11-27 00:00:00'), Timestamp('2021-11-28 00:00:00'), Timestamp('2021-11-29 00:00:00'), Timestamp('2021-11-30 00:00:00'), Timestamp('2021-12-01 00:00:00'), Timestamp('2021-12-02 00:00:00'), Timestamp('2021-12-03 00:00:00'), Timestamp('2021-12-04 00:00:00'), Timestamp('2021-12-05 00:00:00'), Timestamp('2021-12-06 00:00:00'), Timestamp('2021-12-07 00:00:00'), Timestamp('2021-12-08 00:00:00'), Timestamp('2021-12-09 00:00:00'), Timestamp('2021-12-10 00:00:00'), Timestamp('2021-12-11 00:00:00'), Timestamp('2021-12-12 00:00:00'), Timestamp('2021-12-13 00:00:00'), Timestamp('2021-12-14 00:00:00'), Timestamp('2021-12-15 00:00:00'), Timestamp('2021-12-16 00:00:00'), Timestamp('2021-12-17 00:00:00'), Timestamp('2021-12-18 00:00:00'), Timestamp('2021-12-19 00:00:00'), Timestamp('2021-12-20 00:00:00'), Timestamp('2021-12-21 00:00:00'), Timestamp('2021-12-22 00:00:00'), Timestamp('2021-12-23 00:00:00'), Timestamp('2021-12-24 00:00:00'), Timestamp('2021-12-25 00:00:00'), Timestamp('2021-12-26 00:00:00'), Timestamp('2021-12-27 00:00:00'), Timestamp('2021-12-28 00:00:00'), Timestamp('2021-12-29 00:00:00'), Timestamp('2021-12-30 00:00:00'), Timestamp('2021-12-31 00:00:00'), Timestamp('2022-01-01 00:00:00'), Timestamp('2022-01-02 00:00:00'), Timestamp('2022-01-03 00:00:00'), Timestamp('2022-01-04 00:00:00'), Timestamp('2022-01-05 00:00:00'), Timestamp('2022-01-06 00:00:00'), Timestamp('2022-01-07 00:00:00'), Timestamp('2022-01-08 00:00:00'), Timestamp('2022-01-09 00:00:00'), Timestamp('2022-01-10 00:00:00')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 5 ))\n",
        "ax.grid()\n",
        "ax.scatter(date_format,y_value1['Values'])\n",
        "ax.set(xlabel=\"Date\",ylabel=\"recovered case\")\n",
        "date_form = DateFormatter('%d-%m-%y')\n",
        "#print(date_form)\n",
        "ax.xaxis.set_major_formatter(date_form)\n",
        "#ax.xaxis.set_major_locator(mdates.DayLocator(interval = 15))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "RNp2HZGVpFt1",
        "outputId": "09afac11-16a3-4de3-b937-1c2e37e66459"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Time'] = np.arange(len(df1.index))"
      ],
      "metadata": {
        "id": "pGMmAZya_2dS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWllm0R7_2Zw",
        "outputId": "e3ac2829-e1ab-4f04-9214-dc6919b14c34"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Title                                             Values  Time\n",
            "0        UID                                       278822801147     0\n",
            "1       iso2  USUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUSUS...     1\n",
            "2       iso3  USAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAUSAU...     2\n",
            "3      code3                                            2788882     3\n",
            "4       FIPS                                        110099539.0     4\n",
            "..       ...                                                ...   ...\n",
            "726   1/6/22                                           59388686   726\n",
            "727   1/7/22                                           59767418   727\n",
            "728   1/8/22                                           60090560   728\n",
            "729   1/9/22                                           61556085   729\n",
            "730  1/10/22                                           62308472   730\n",
            "\n",
            "[731 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import scale \n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Training data\n",
        "X = df1.loc[11:500, ['Time']]  # features\n",
        "y = df1.loc[11:500, 'Values']  # target\n",
        "\n",
        "reg = Lasso(alpha=1)\n",
        "reg.fit(X,y)\n",
        "\n",
        "y_pred1 = pd.Series(reg.predict(X), index=X.index)\n",
        "print(y_pred1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2ajyYjI0ZST",
        "outputId": "eb4c406e-30bf-48ae-b8be-42cc920b79ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11    -7.429776e+06\n",
            "12    -7.349639e+06\n",
            "13    -7.269502e+06\n",
            "14    -7.189365e+06\n",
            "15    -7.109229e+06\n",
            "           ...     \n",
            "496    3.143659e+07\n",
            "497    3.151672e+07\n",
            "498    3.159686e+07\n",
            "499    3.167700e+07\n",
            "500    3.175713e+07\n",
            "Length: 490, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = 10**np.linspace(10,-2,100)*0.5\n",
        "\n",
        "lasso = Lasso(max_iter = 10000, normalize = True)\n",
        "coefs = []\n",
        "\n",
        "for a in alphas:\n",
        "    lasso.set_params(alpha=a)\n",
        "    lasso.fit(scale(X), y)\n",
        "    coefs.append(lasso.coef_)\n",
        "    \n",
        "ax = plt.gca()\n",
        "ax.plot(alphas*2, coefs)\n",
        "ax.set_xscale('log')\n",
        "plt.axis('tight')\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('weights')\n",
        "\n",
        "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
        "lassocv.fit(X, y)\n",
        "\n",
        "lasso.set_params(alpha=lassocv.alpha_)\n",
        "lasso.fit(X, y)\n",
        "mean_squared_error(y, lasso.predict(X))\n",
        "pd.Series(lasso.coef_, index=X.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "pxYJGQEc02ES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e73d87c0-0972-46a7-a768-37aa2fc1374e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time    79000.912103\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Training data\n",
        "X = df1.loc[11:500, ['Time']]  # features\n",
        "y = df1.loc[11:500, 'Values']  # target\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "y_pred = pd.Series(model.predict(X), index=X.index)"
      ],
      "metadata": {
        "id": "vWydCp29_2XJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_params = dict(\n",
        "    style=\".-\",\n",
        "    legend=True,\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 5 ))\n",
        "ax.grid()\n",
        "ax.scatter(date_format,y_value1['Values'])\n",
        "ax.set(xlabel=\"Date\",ylabel=\"Recovered case\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 5 ))\n",
        "ax = y.plot(**plot_params)\n",
        "ax = y_pred.plot(ax=ax, linewidth=3)\n",
        "ax.set_title('LR for recovered cases globally');\n",
        "ax.set(xlabel=\"Days since 1/22/2020\",ylabel=\"No. of case\")\n",
        "ax.grid();\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "hutUSjEw_2Up",
        "outputId": "d6d00ec0-5898-4da6-d4b8-5277c3ad80d5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JnTeJq-N_2IR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  "
      ],
      "metadata": {
        "id": "aIUT39nUuP46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}